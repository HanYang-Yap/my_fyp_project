import asyncio
import json
import os
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Dict, Optional

from firebase_admin import firestore
from flask import jsonify
from IPython.display import display
from langchain.prompts import ChatPromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from redis_client import r
from services.evaluation_service import EvaluationService

REDIS_TTL = 7200  # 1 hour

## Langchainè¨­ç½®

with open("static/evaluation_criteria.json", "r", encoding="utf-8") as f:
    evaluation_criteria = json.load(f)
    
def setup_langchain():
    os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
    if not os.environ.get("OPENAI_API_KEY"):
        # è‹¥æ²’è¨­ç½®OPENAI_API_KEYï¼Œå¾…åŠ 
        pass
    # model = ChatOpenAI(model="gpt-4o-mini")
    model = ChatOpenAI(model="gpt-4o")
    return model

model = setup_langchain()

async def load_pdf(file_path: str, file_id: str, user_id: str) -> str:
    """
    è®€å–PDFä¸¦è¿”å›åˆ†æ®µåˆ—è¡¨
    Args:
        file_path (str): PDFæ–‡ä»¶è·¯å¾‘/å¾ŒçºŒé€£æ¥å¯ä¸ç”¨
        file_id (str): æ–‡ä»¶å”¯ä¸€id
        user_id (str): ä½¿ç”¨è€…ID
    Returns:
        list: æ–‡ä»¶å…§å®¹çš„æ®µè½åˆ—è¡¨
    """
    try:
        loader = PyPDFLoader(file_path)
        pages = []
        async for page in loader.alazy_load():
            pages.append(page)

        full_text = ""
        for page in pages:
            full_text += page.page_content.replace("\n", "").replace(" ", "")
            
        # ä½¿ç”¨divide_textå°‡æ–‡æœ¬åˆ†æ®µ
        dividing_list = divide_text_noSuggestion(full_text)

        # å„²å­˜ dividing_list åˆ° Redis
        r.set(f"{user_id}:{file_id}:dividing", json.dumps(dividing_list), ex=REDIS_TTL)
        # å„²å­˜ summary åˆ° Redis
        r.set(f"file:{file_id}:summary", json.dumps(full_text), ex=REDIS_TTL)

        return dividing_list
    except Exception as e:
        raise ValueError(f"PDFåŠ è¼‰å¤±æ•—: {str(e)}")

    # æ–¹æ³•äºŒï¼šå¾ Firebase è®€æª” å…ˆè¨»è§£
    # db = firestore.client()
    # bucket = storage_client.bucket(Config.FIREBASE_STORAGE_BUCKET)
    # blob = bucket.blob(file_path)
    # blob.download_to_filename(file_path)
    # loader = PyPDFLoader(file_path)
    # pages = []
    # async for page in loader.alazy_load():
    #     pages.append(page)
    # summary = ""
    # for page in pages:
    #     content = page.page_content.replace("\n", "").replace(" ", "")
    #     summary += content
    # r.set(f"file:{file_id}:summary", summary, ex=REDIS_TTL)
    # return summary

def get_dividingList_redis(user_id:str, file_id: str) -> str:
    data = r.get(f"{user_id}:{file_id}:dividing")
    if not data:
        raise ValueError("æŸ¥ç„¡å¿«å–è³‡æ–™ï¼Œè«‹å…ˆå‘¼å« /allSuggestion å»ºç«‹æ®µè½")
    return json.loads(data)

def get_summary_redis(file_id: str) -> str:
    data = r.get(f"file:{file_id}:summary")
    if not data:
        raise ValueError("æŸ¥ç„¡å¿«å–è³‡æ–™ï¼Œè«‹å…ˆå‘¼å« /allSuggestion å»ºç«‹æ®µè½")
    return json.loads(data)

def update_summary_redis(file_id: str, new_summary: str) -> None:
    if not file_id or not new_summary:
        raise ValueError("ç¼ºå°‘å¿…è¦çš„fileIdæˆ–fileContent")
    r.set(f"file:{file_id}:summary", new_summary, ex=REDIS_TTL)
    return True

## ä¸€ã€åˆæ­¥é–±è®€èˆ‡è¨ºæ–·

def generate_learning_diagnosis(
    file_id: str,
    department: str,
    requirements: str,
    summary: str
) -> str:
    """
    è¨ºæ–·å­¸ç”Ÿå­¸ç¿’æ­·ç¨‹ä¸¦æä¾›å„ªåŒ–å»ºè­°
    
    Args:
        department (str): ç›®æ¨™ç³»æ‰€åç¨±
        requirements (str): ç³»æ‰€è¦æ±‚ä»£è™Ÿ
        summary (str): å­¸ç¿’æ­·ç¨‹ç¸½çµ/å¤šå…ƒè¡¨ç¾ç¶œæ•´å¿ƒå¾—
        problem (Optional[str], optional): ä½¿ç”¨è€…è‡ªèº«èªç‚ºå·²æœ‰çš„ç¼ºé™·æˆ–ç–‘å•. Defaults to None.
    
    Returns:
        str: è¨ºæ–·å ±å‘Š
    """
    # å®šç¾©å¯ç”¨çš„é …ç›®
    sections = {
        "F": "Fï¼šé«˜ä¸­è‡ªä¸»å­¸ç¿’è¨ˆç•«èˆ‡æˆæœ",
        "G": "Gï¼šç¤¾åœ˜æ´»å‹•ç¶“é©—",
        "H": "Hï¼šæ“”ä»»å¹¹éƒ¨ç¶“é©—",
        "I": "Iï¼šæœå‹™å­¸ç¿’ç¶“é©—",
        "J": "Jï¼šç«¶è³½è¡¨ç¾",
        "K": "Kï¼šéä¿®èª²ç´€éŒ„ä¹‹æˆæœä½œå“",
        "L": "Lï¼šæª¢å®šè­‰ç…§",
        "M": "Mï¼šç‰¹æ®Šå„ªè‰¯è¡¨ç¾è­‰æ˜",
        "N": "Nï¼šå¤šå…ƒè¡¨ç¾ç¶œæ•´å¿ƒå¾—",
        "O": "Oï¼šé«˜ä¸­å­¸ç¿’æ­·ç¨‹åæ€",
        "P": "Pï¼šå°±è®€å‹•æ©Ÿ",
        "Q": "Qï¼šæœªä¾†å­¸ç¿’è¨ˆç•«èˆ‡ç”Ÿæ¶¯è¦åŠƒ"
    }
    
    selected_sections = "\n".join([
        sections[char] for char in requirements if char in sections
    ])

    system_template = """
    ä½ æ˜¯ä¸€ä½å°ˆç²¾æ–¼å”åŠ©é«˜ä¸­ç”Ÿå„ªåŒ–å¤§å­¸å…¥å­¸ç”³è«‹å­¸ç¿’æ­·ç¨‹çš„å°ˆå®¶ã€‚ä½ çš„ç›®æ¨™æ˜¯è¨ºæ–·ä¸¦å„ªåŒ–å­¸ç”Ÿçš„ç”³è«‹è³‡æ–™ï¼Œç”³è«‹ç›®æ¨™ç‚º {department}ï¼Œè³‡æ–™å…§å®¹éœ€ç¬¦åˆè©²æ ¡ç³»è¦å®šæŒ‡æ¨™ï¼š{requirements}ï¼Œå­—æ¯æ„ç¾©å¦‚ä¸‹ã€‚

    {selected_sections}

    è¨ºæ–·è¦æ±‚: è«‹é‡å°æ¯ä¸€æ®µè½é€²è¡Œä»¥ä¸‹å…­é …è¨ºæ–·ï¼Œä¸¦æä¾›å…·é«”å»ºè­°ï¼Œä½†åªéœ€è¼¸å‡ºå…­å€‹æœ€åš´é‡çš„è¨ºæ–·å•é¡Œï¼Œä»¥æ¸…æ¥šè¡¨é”æ”¹å–„æ–¹å‘ã€‚
    1. éŒ¯å­—èˆ‡æ¨™é»ç¬¦è™Ÿï¼šæª¢æŸ¥èªæ³•ã€éŒ¯åˆ¥å­—æˆ–æ ¼å¼å•é¡Œï¼ŒæŒ‡å‡ºä¸¦å»ºè­°ä¿®æ­£ã€‚
    2. åé¡Œéƒ¨åˆ†ï¼šæª¢æŸ¥æ®µè½æ˜¯å¦åé›¢ä¸»é¡Œï¼Œä¸¦å»ºè­°åˆªæ”¹æˆ–èª¿æ•´å…§å®¹ä»¥å›åˆ°æ ¸å¿ƒç›®æ¨™ã€‚
    3. ç²¾ç°¡å»ºè­°ï¼šæŒ‡å‡ºå†—é•·æˆ–é‡è¤‡çš„éƒ¨åˆ†ï¼Œæä¾›ç°¡æ½”è¡¨é”çš„å»ºè­°ã€‚
    4. å¢é•·å»ºè­°ï¼šå¦‚å…§å®¹ä¸è¶³ï¼Œå»ºè­°è£œå……èˆ‡ç”³è«‹ç§‘ç³»ç›¸é—œã€èƒ½çªé¡¯å­¸ç”Ÿç‰¹é»çš„å…§å®¹ã€‚
    5. æ¶æ§‹æª¢æŸ¥ï¼šæª¢æŸ¥æ®µè½çš„é‚è¼¯æ€§èˆ‡å±¤æ¬¡æ€§ï¼ŒæŒ‡å‡ºä¸æ¸…æ™°çš„éƒ¨åˆ†ä¸¦å»ºè­°æ”¹å–„ã€‚
    6. å®Œæ•´åº¦ï¼šç¢ºèªæ˜¯å¦æ¶µè“‹è©²æ®µè½æ‡‰æœ‰çš„å¿…è¦å…§å®¹ï¼ŒæŒ‡å‡ºç¼ºå¤±ä¸¦æä¾›å»ºè­°è£œå……çš„æ–¹å‘ã€‚

    æŒ‡å°ç›®æ¨™: æ ¹æ“šè¨ºæ–·çµæœï¼Œæå‡ºå…·é«”å»ºè­°ï¼Œä½¿æ–‡å­—æ›´åŠ æµæš¢ä¸”é‚è¼¯æ¸…æ™°ï¼Œä¸¦çªé¡¯å­¸ç”Ÿå€‹äººç‰¹é»èˆ‡å…¶ç”³è«‹ç§‘ç³»çš„ç›¸é—œæ€§ã€‚ç¢ºä¿æ•´é«”èªè¨€ç¬¦åˆå°ˆæ¥­å¯©æ ¸æ¨™æº–ã€‚

    å­¸ç¿’æ­·ç¨‹ç¸½çµ/å¤šå…ƒè¡¨ç¾ç¶œæ•´å¿ƒå¾—:
    {summary}

    è¼¸å‡ºè¦å‰‡: è«‹æ ¹æ“šè¨ºæ–·éç¨‹ï¼ŒæŒ‡å‡ºæœ€åš´é‡çš„å…­å€‹å•é¡Œè¨ºæ–·ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹ç¯„ä¾‹æ ¼å¼ç°¡æ˜å‘ˆç¾ã€‚å…¶ä¸­å­—æ¯èˆ‡æ•¸å­—ä»£è™Ÿæ ¹æ“šä»¥ä¸Šè¦å‰‡åŸ·è¡Œã€‚
    è¼¸å‡ºæ ¼å¼: [å­—æ¯ä»£è™Ÿ][æ•¸å­—ä»£è™Ÿ]:[å•é¡Œé¡å‹][å•é¡Œè¨ºæ–·çµæœ]ã€‚
    è¼¸å‡ºç¯„ä¾‹:
    1. O5ï¼š[æ¶æ§‹æª¢æŸ¥]åœ¨"æŸæŸ"æ®µè½ä¸­ï¼Œå°æ–¼...ã€‚
    2. P2ï¼š[åé¡Œéƒ¨åˆ†]åœ¨"æŸæŸ"æ®µè½ä¸­æåˆ°...å»ºè­°...ã€‚
    3. ...
    æœ€çµ‚çµæœ: ç¸½å…±æœƒæœ‰å…­æ¢å•é¡Œé¡å‹èˆ‡å…¶å•é¡Œæè¿°èˆ‡è¨ºæ–·ã€‚
    
    """

    prompt_template = ChatPromptTemplate.from_messages([("system", system_template)])
    prompt = prompt_template.invoke({
        "department": department,
        "requirements": requirements,
        "selected_sections": selected_sections,
        "summary": summary
    })

    response = model.invoke(prompt)
    return response.content

def process_diagnose_request(user_id: str, file_id: str, department_and_type: str) -> tuple:
    """
    è™•ç†è¨ºæ–·è«‹æ±‚ï¼Œè§£æè³‡æ–™ä¸¦åŸ·è¡Œè¨ºæ–·
    Args:
        user_id (str): ä½¿ç”¨è€…ID
        file_id (str): æª”æ¡ˆID
        department_and_type (str): ç³»æ‰€èˆ‡é¡å‹å­—ä¸²ï¼Œæ ¼å¼ç‚º "å­¸æ ¡-ç³»æ‰€-é¡å‹"
    Returns:
        tuple: (æª”æ¡ˆå…§å®¹, è¨ºæ–·çµæœ)
    """

    parts = department_and_type.split("-")
    if len(parts) < 2:
        raise ValueError("ç³»æ‰€é¡å‹æ ¼å¼ç„¡æ•ˆ")
        
    department = "-".join(parts[:-1])  # å­¸æ ¡å’Œç³»æ‰€åç¨±å¯èƒ½åŒ…å«é€£å­—è™Ÿ
    requirements = parts[-1]
    
    # æª”æ¡ˆè·¯å¾‘ #æœªä¾†æ›´æ”¹
    # file_path = "C:\\Users\\owner\\Documents\\NCCU\\å°ˆé¡Œ\\åˆæ­¥é–±è®€èˆ‡è¨ºæ–·ç”¨çš„.pdf"
    # file_path = "C:\\Users\\sophi\\OneDrive\\æ¡Œé¢\\åˆæ­¥é–±è®€èˆ‡è¨ºæ–·ç”¨çš„(1).pdf"
    file_path = "\\Users\\hy\\Downloads\\åˆæ­¥é–±è®€èˆ‡è¨ºæ–·ç”¨çš„(1).pdf"
    
    # è®€å–æª”æ¡ˆå…§å®¹ åŒæ­¥å‘¼å«éåŒæ­¥å‡½æ•¸
    dividing_list = run_async_function(lambda: load_pdf(file_path, file_id, user_id))
    
    # å°‡å®Œæ•´æ–‡æœ¬é€£æ¥èµ·ä¾†ç”¨æ–¼è¨ºæ–·
    file_content = "\n\n".join(dividing_list)

    diagnosed_result = generate_learning_diagnosis(
        file_id=file_id,
        department=department,
        requirements=requirements,
        summary=file_content
    )
    
    # å°‡diagnosed_resultå­˜å…¥Redis
    r.set(f"file:{file_id}:diagnosed_result", diagnosed_result, ex=REDIS_TTL)
    # å°‡departmentå­˜å…¥Redisï¼Œsummaryåƒ…ä¾›ä½¿ç”¨è€…æ–¼åˆæ­¥è¨ºæ–·ä¿®æ”¹å®Œå¾Œã€å‚³éçµ¦allSuggestion
    r.set(f"file:{file_id}:department", department, ex=REDIS_TTL)

    return file_content, diagnosed_result

## äºŒã€ç”Ÿæˆå¼•å°å¼å•é¡Œ

def evaluate_content_quality(diagnosis_result: str) -> str:
    """
    è©•ä¼°å…§å®¹å“è³ªçš„ä¸‰å€‹ç¶­åº¦
    
    Args:
        diagnosis_result (str): åˆæ­¥è¨ºæ–·çµæœ
        
    Returns:
        str: å…§å®¹å“è³ªè©•ä¼°çµæœ
    """
    # ç¢ºä¿ model å·²åˆå§‹åŒ–
    model = setup_langchain()
    
    system_template_quality_check = """
    ä»»å‹™ï¼š

    è«‹æ ¹æ“šæä¾›çš„å­¸ç”Ÿåˆæ­¥é–±è®€èˆ‡è¨ºæ–·æª”æ¡ˆ{diagnosis_result}ï¼Œè©•ä¼°å…¶å…§å®¹å“è³ªï¼Œä¸¦é‡å°ä¸‰å€‹ç¶­åº¦é€²è¡Œè¨ºæ–·ï¼š

    1. å¿…è¦æ€§ (é«˜)ï¼šæ˜¯å¦ç¼ºå°‘å­¸ç³»æˆ–å­¸æ ¡è¦æ±‚çš„é—œéµå…§å®¹ï¼ˆå¦‚å­¸ç¿’å‹•æ©Ÿã€æœªä¾†è¦åŠƒç­‰ï¼‰ï¼Ÿ
    2. å®Œæ•´æ€§ (ä¸­)ï¼šå…§å®¹æ˜¯å¦éæ–¼ç°¡çŸ­ã€ç± çµ±ï¼Œç¼ºå°‘ç´°ç¯€æˆ–å…·é«”äº‹ä¾‹ï¼Ÿ
    3. æ“´å±•æ€§ (ä½)ï¼šå…§å®¹æ˜¯å¦å®Œæ•´ä½†ç•¥é¡¯å¹³æ·¡ï¼Œç¼ºå°‘å€‹äººç‰¹è‰²ï¼Ÿ

    è¼¸å‡ºæ ¼å¼ï¼š
        "å¿…è¦æ€§": å¿…è¦æ€§è¨ºæ–·çµæœ
        "å®Œæ•´æ€§": å®Œæ•´æ€§æ•´æ®µçµæœ
        "æ“´å±•æ€§": æ“´å±•æ€§è¨ºæ–·çµæœ
        "çµè«–": ç°¡è¿°ä»¥ä¸Šå•é¡Œèˆ‡å¯æ”¹é€²çš„éƒ¨åˆ†
    """

    prompt_quality_check = ChatPromptTemplate.from_messages([
        ("system", system_template_quality_check)
    ])

    quality_check_prompt = prompt_quality_check.invoke({"diagnosis_result": diagnosis_result})
    quality_check_response = model.invoke(quality_check_prompt)
    return quality_check_response.content

def identify_student_issues(stu_problem: str) -> str:
    """
    è­˜åˆ¥å­¸ç”Ÿçš„æ ¸å¿ƒå•é¡Œ
    
    Args:
        stu_problem (str): å­¸ç”Ÿæå‡ºçš„å•é¡Œ
        
    Returns:
        str: è­˜åˆ¥å‡ºçš„æ ¸å¿ƒå•é¡Œæ¸…å–®
    """
    # ç¢ºä¿ model å·²åˆå§‹åŒ–
    model = setup_langchain()
    
    system_template_identify_issues = """
    ä»»å‹™ï¼š

    å­¸ç”Ÿå¡«å¯«çš„è‡ªèº«ç–‘å•æˆ–å­¸ç¿’ç¼ºé™·æ˜¯"{stu_problem}"ï¼Œè«‹å¾ä»¥ä¸Šçš„éœ€æ±‚åˆ—å‡º1-3å€‹æ ¸å¿ƒå•é¡Œã€‚

    é™åˆ¶æ¢ä»¶ï¼š
    1. å•é¡Œæ‡‰ä¾†è‡ªå­¸ç”Ÿçš„å¡«å¯«å…§å®¹ï¼Œå‹¿é¡å¤–æ¨æ¸¬ã€‚
    2. åªæŒ‘é¸æœ€å¤šä¸‰å€‹èˆ‡å­¸ç¿’æ­·ç¨‹é«˜åº¦ç›¸é—œçš„å•é¡Œã€‚

    è¼¸å‡ºæ ¼å¼é™åˆ¶å¦‚ä¸‹ï¼Œä¸è¦æœ‰ç©ºè¡Œæˆ–æ¨™è™Ÿï¼š
    ["å­¸ç”Ÿç–‘å• 1", "å­¸ç”Ÿç–‘å• 2", "å­¸ç”Ÿç–‘å• 3"]
    """

    prompt_identify_issues = ChatPromptTemplate.from_messages([
        ("system", system_template_identify_issues)
    ])

    identify_issues_prompt = prompt_identify_issues.invoke({"stu_problem": stu_problem})
    identify_issues_response = model.invoke(identify_issues_prompt)
    return identify_issues_response.content

def generate_guided_questions(previous_suggestion: str, diagnosis_result: str, student_problem: str) -> list[str]:
    """
    ç”Ÿæˆå¼•å°å¼å•é¡Œæ¸…å–®
    
    Args:
        previous_suggestion (str): åŸæœ‰çš„å…·é«”å»ºè­°
        diagnosis_result (str): ä¸‰ç¶­åº¦è¨ºæ–·çµæœ
        student_problem (str): å­¸ç”Ÿå•é¡Œ
        
    Returns:
        List[str]: å¼•å°å¼å•é¡Œæ¸…å–®
    """
    # ç¢ºä¿ model å·²åˆå§‹åŒ–
    model = setup_langchain()
    
    system_template_questions = """
    ä»»å‹™ï¼š
    åŸæœ‰çš„å…·é«”å»ºè­°ç‚º:{previous_suggestion}
    ä¸‰ç¶­åº¦è¨ºæ–·çµæœ:{diagnosis_result}ã€èˆ‡å­¸ç”Ÿå•é¡Œ"{problem}"æå‡ºæœ€å¤šåå€‹å…·é«”çš„å¼•å°å¼å•é¡Œï¼Œå¹«åŠ©å­¸ç”Ÿå®Œå–„å€‹äººåŒ–å­¸ç¿’æ­·ç¨‹ï¼Œä»¥ä¾›å­¸ç”Ÿå®Œå–„å¤§å­¸å…¥å­¸æª”æ¡ˆã€‚
    å•é¡Œæ‡‰è©²å¹«åŠ©å­¸ç”Ÿï¼š
    1. æ·±å…¥åæ€å€‹äººç¶“æ­·
    2. å‡¸é¡¯ç¨ç‰¹æ€§å’Œæˆé•·
    3. é€£çµå­¸ç¿’å‹•æ©Ÿèˆ‡æœªä¾†è¦åŠƒ
    æ³¨æ„å•é¡Œé¿å…éæ–¼æ”çµ±èˆ‡æ¦‚æ‹¬ã€‚

    æœ€å¾Œï¼Œè«‹å‹™å¿…è¦è¼¸å‡ºæ ¼å¼æˆä»¥ä¸‹å½¢å¼ã€ç”¨é€—è™Ÿåˆ†é–‹:
    å•é¡Œ1, å•é¡Œ2, å•é¡Œ3, ..., å•é¡Œ10
    """

    prompt_template_questions = ChatPromptTemplate.from_messages([
        ("system", system_template_questions)
    ])

    combined_input = {
        "previous_suggestion": previous_suggestion,
        "diagnosis_result": diagnosis_result,
        "problem": student_problem
    }
    
    questions_prompt = prompt_template_questions.invoke(combined_input)
    questions_response = model.invoke(questions_prompt)
    
    # è§£æå•é¡Œæ¸…å–®
    return parse_questions(questions_response.content)

def parse_questions(questions_string: str) -> list[str]:
    """
    è§£æå•é¡Œå­—ä¸²ç‚ºæ¸…å–®
    
    Args:
        questions_string (str): å•é¡Œå­—ä¸²ï¼Œä»¥é€—è™Ÿåˆ†éš”
        
    Returns:
        List[str]: å•é¡Œæ¸…å–®
    """
    if "ï¼š" in questions_string:
        questions_string = questions_string.split("ï¼š", 1)[1].strip()
    
    questions = [q.strip() for q in questions_string.split(",")]
    clean_questions = []
    
    for q in questions:
        if "." in q:
            parts = q.split(".")
            clean_questions.append(parts[0].strip())
            if len(parts) > 1 and parts[1].strip():
                clean_questions.append(parts[1].strip())
        else:
            clean_questions.append(q)
            
    clean_questions = [q for q in clean_questions if q]
    return clean_questions

def gen_questions(file_id: str, student_problem: Optional[str] = None) -> Dict:
    """ç”Ÿæˆå¼•å°å•é¡Œ"""
    # å¾ Redis ç²å–è¨ºæ–·çµæœ,æª”æ¡ˆå…§å®¹å’Œç³»æ‰€åç¨±
    diagnosed_result = r.get(f"file:{file_id}:diagnosed_result")
    if not diagnosed_result:
        raise ValueError("è«‹å…ˆé€²è¡Œè¨ºæ–·ï¼Œç„¶å¾Œå†é€²è¡Œå…¨é¢è©•ä¼°ã€‚")
    
    file_content = r.get(f"file:{file_id}:summary")
    if not file_content:
        raise ValueError("è«‹å…ˆè®€å– PDF æª”æ¡ˆï¼Œç„¶å¾Œå†é€²è¡Œè¨ºæ–·ã€‚")

    department = r.get(f"file:{file_id}:department")
    if not department:
        raise ValueError("è«‹å…ˆè®€å–ç³»æ‰€åç¨±ï¼Œç„¶å¾Œå†é€²è¡Œå…¨é¢è©•ä¼°ã€‚")
    
    # è©•ä¼°å…§å®¹å“è³ª
    quality_assessment = evaluate_content_quality(diagnosed_result)
    
    # è­˜åˆ¥å­¸ç”Ÿå•é¡Œ
    if student_problem:
        core_issues = identify_student_issues(student_problem)
    else:
        core_issues = "[]"  # ç©ºæ¸…å–®
    
    # ç”Ÿæˆå¼•å°å•é¡Œ
    guided_questions = generate_guided_questions(diagnosed_result, quality_assessment, core_issues)
    
    # çµ„åˆæ‰€æœ‰çµæœ
    results = {
        "coreIssues": core_issues,
        "guidedQuestions": guided_questions
    }
    
    return results

def save_qa(QA_response: str, user_id: str, file_id: str) -> None:
    """
    å„²å­˜å¼•å°å•é¡Œèˆ‡å­¸ç”Ÿå›ç­”
    Args:
        QA_response (str): å¼•å°å•é¡Œèˆ‡å­¸ç”Ÿå›ç­”çš„å­—ä¸²
        user_id (str): ä½¿ç”¨è€…ID
        file_id (str): æª”æ¡ˆID
    """
    
    if QA_response!= "":
        # å„²å­˜åˆ° Redis ä¸­ï¼Œè¨­å®š TTL ç‚º 1 å°æ™‚
        r.set(f"{user_id}:{file_id}:QA_response", QA_response, ex=REDIS_TTL)
        return True
    return False


## ä¸‰ã€æª¢æŸ¥å…¨æ–‡é‚è¼¯èˆ‡æµæš¢åº¦

def all_check(summary: str) -> Dict[str, Any]:
    """
    åˆ†ææ–‡æœ¬é•·åº¦ä¸¦æä¾›å­—æ•¸å»ºè­°å’Œæµæš¢åº¦æª¢æŸ¥
    Args:
        summary (str): éœ€è¦åˆ†æçš„æ–‡æœ¬å…§å®¹
    Returns:
        Dict: åŒ…å«å­—æ•¸çµ±è¨ˆã€å»ºè­°å’Œå…¨æ–‡æª¢æŸ¥çµæœçš„å­—å…¸
    """
    def count_words(text: str) -> int:
        """è¨ˆç®—æ–‡æœ¬å­—æ•¸"""
        return len(text.split())

    def count_characters(text: str) -> int:
        """è¨ˆç®—æ–‡æœ¬å­—å…ƒæ•¸"""
        return len(text)

    # è¨ˆç®—å­—æ•¸
    word_count = count_words(summary)
    char_count = count_characters(summary)

    # å­—æ•¸å»ºè­°
    if word_count > 800:
        word_feedback = "âš ï¸ å­—æ•¸è¶…æ¨™ï¼Œå»ºè­°ç²¾ç°¡éƒ¨åˆ†å…§å®¹ï¼ˆå£“ç¸® 50-100 å­—ï¼‰ã€‚"
    elif word_count < 600:
        word_feedback = "âš ï¸ å†…å®¹éæ–¼ç°¡ç•¥ï¼Œå»ºè­°æ“´å……éƒ¨åˆ†ç´°ç¯€ï¼ˆå¢åŠ  50-100 å­—ï¼‰ã€‚"
    else:
        word_feedback = "âœ… å­—æ•¸é©ä¸­ï¼Œç„¡éœ€ç‰¹åˆ¥ä¿®æ”¹é•·åº¦ã€‚"

    # å­—æ•¸çµ±è¨ˆæ‘˜è¦
    word_count_summary = f"""
    ğŸ“Œ å­—æ•¸çµ±è¨ˆ
    - ç¸½å­—æ•¸ï¼š{word_count} å­—
    - ç¸½å­—å…ƒæ•¸ï¼š{char_count} å­—å…ƒ
    - å­—æ•¸å»ºè­°ï¼š{word_feedback}
    """

    # æª¢æŸ¥é‚è¼¯èˆ‡æµæš¢åº¦çš„ Prompt æ¨¡æ¿
    all_template_check = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡å­—ç·¨è¼¯å°ˆå®¶ï¼Œè² è²¬æª¢æŸ¥å¤§å­¸å…¥å­¸æ›¸é¢è³‡æ–™ï¼Œç¢ºä¿å…§å®¹é‚è¼¯æ¸…æ™°ã€è©³ç´°ä¸”å…·èªªæœåŠ›ã€‚è«‹æ ¹æ“šä»¥ä¸‹è¦æ±‚åˆ†æå…¨æ–‡ï¼š
    1. æ®µè½é–“çš„é‚è¼¯é—œè¯æ€§èˆ‡è‡ªç„¶éæ¸¡ï¼šç¢ºä¿æ¯æ®µä¹‹é–“çš„éŠœæ¥é †æš¢ï¼Œæ²’æœ‰çªå…€çš„è·³èºã€‚
    2. ç´°ç¯€çš„æ·±åº¦èˆ‡æ”¯æ’åŠ›ï¼šæª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„ä¾‹è­‰ä¾†æ”¯æŒè«–é»ã€‚
    3. èˆ‡å­¸æ ¡ç‰¹è‰²æˆ–ç³»æ‰€æ–¹å‘çš„é—œè¯ï¼šç¢ºèªæ˜¯å¦èƒ½å±•ç¾å°è©²å­¸æ ¡æˆ–ç³»æ‰€çš„ç†è§£èˆ‡é©é…æ€§ã€‚
    4. è¡¨é”æ–¹å¼çš„æµæš¢èˆ‡ç²¾æº–ï¼šä¿®æ­£å†—é•·ã€æ¨¡ç³Šæˆ–èªæ„ä¸æ¸…çš„å¥å­ã€‚

    æ­¥é©Ÿ
    - å…ˆé–±è®€å…¨æ–‡{origin_text}ï¼Œåˆ†ææ¯å€‹æ®µè½çš„ä¸»è¦å…§å®¹ã€‚
    - ä¾æ“š{word_count_summary}å¾—çŸ¥å­—æ•¸æ”¹é€²çš„å»ºè­°
    - é‡å°å…¨æ–‡æä¾› ç¸½é«”æ”¹é€²æ–¹å‘ï¼Œç¢ºä¿ä¸åŒæ®µè½ä¸æœƒéåº¦é‡è¤‡å…§å®¹ã€‚
    - ç‚ºæ¯å€‹æ®µè½æ¨™è¨˜ éœ€è¦æ”¹å–„çš„é‡é»ï¼Œä¾‹å¦‚ï¼š
        - æ®µè½ 1ï¼ˆé–‹é ­ï¼‰ï¼šã€Œéœ€æ›´æ˜ç¢ºè¡¨é”å‹•æ©Ÿã€‚ã€
        - æ®µè½ 3ï¼ˆå­¸ç§‘é€£çµï¼‰ï¼šã€Œæ‡‰å¼·èª¿è©²å­¸æ ¡çš„èª²ç¨‹ç‰¹è‰²ã€‚ã€
        - æ®µè½ 5ï¼ˆçµå°¾ï¼‰ï¼šã€Œå¯ä»¥æ›´æœ‰åŠ›åœ°ç¸½çµå‹•æ©Ÿã€‚ã€

    è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºç´”JSONå›æ‡‰ï¼š
    {{
        "å…¨æ–‡ç¸½é«”å»ºè­°": {{
            "é‚è¼¯èˆ‡éæ¸¡": "...",
            "ç´°ç¯€æ·±åº¦": "...",
            "å­¸ç³»é—œè¯": "...",
            "è¡¨é”æµæš¢æ€§": "...",
            "å­—æ•¸å»ºè­°": "..."
        }},
        "å„æ®µè½æ”¹é€²æ–¹å‘": {{
            "æ®µè½ 1": "...",
            "æ®µè½ 2": "...",
            ...
        }}
    }}
    """

    # å‰µå»º Prompt æ¨¡æ¿
    prompt_template_check = ChatPromptTemplate.from_messages([
        ("system", all_template_check)
    ])
    
    # èª¿ç”¨æ¨¡å‹é€²è¡Œåˆ†æ
    check_prompt = prompt_template_check.invoke({
        "origin_text": summary,
        "word_count_summary": word_count_summary
    })
    check_response = model.invoke(check_prompt)

    try:
        # å˜—è©¦è§£æéŸ¿æ‡‰ç‚º JSON
        flow_analysis = json.loads(check_response.content)
    except json.JSONDecodeError:
        # è‹¥è§£æå¤±æ•—ï¼Œå‰µå»ºä¸€å€‹é è¨­çµæ§‹
        flow_analysis = {
            "å…¨æ–‡ç¸½é«”å»ºè­°": {
                "é‚è¼¯èˆ‡éæ¸¡": "ç„¡æ³•è‡ªå‹•è§£æ",
                "ç´°ç¯€æ·±åº¦": "ç„¡æ³•è‡ªå‹•è§£æ",
                "å­¸ç³»é—œè¯": "ç„¡æ³•è‡ªå‹•è§£æ",
                "è¡¨é”æµæš¢æ€§": "ç„¡æ³•è‡ªå‹•è§£æ",
                "å­—æ•¸å»ºè­°": word_feedback
            },
            "å„æ®µè½æ”¹é€²æ–¹å‘": {}
        }

    # çµ„åˆçµæœ
    result = {
        "å­—æ•¸çµ±è¨ˆ": {
            "ç¸½å­—æ•¸": word_count,
            "ç¸½å­—å…ƒæ•¸": char_count,
            "å­—æ•¸å»ºè­°": word_feedback
        },
        "æµæš¢åº¦åˆ†æ": flow_analysis
    }

    return result

## å››ã€é€æ®µæ·±å…¥æ”¹å¯«

def divide_text_noSuggestion(text: str) -> list:
    #é€æ®µæ·±å…¥é åˆ†æ®µ
    system_template = """
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡æœ¬åˆ‡å‰²å·¥å…·ï¼Œè«‹æ ¹æ“šçµ¦å®šçš„æ–‡ç« å…§å®¹ï¼Œåš´æ ¼ä¾ç…§4è‡³6æ®µè½æ•¸ï¼Œå°‡æ–‡ç« å…§å®¹æ‹†åˆ†æˆæœ‰æ„ç¾©çš„æ®µï¼Œè‹¥æ®µè½å«æœ‰æ¨™é¡Œè«‹å°‡æ¨™é¡Œä¹Ÿæ¶µè“‹å…¥è©²æ®µè½(æ¨™é¡Œèˆ‡æ®µè½é–“æœ‰ç©ºè¡Œä¹Ÿè¦è·Ÿè‘—ç©ºè¡Œ)ã€‚
    æ–‡ç« ï¼š{full_text}
    è«‹ä¸€å®šè¦å›å‚³ listæ ¼å¼å¦‚ä¸‹
    ["é€™æ˜¯ç¬¬ä¸€æ®µå…§å®¹",é€™æ˜¯ç¬¬äºŒæ®µå…§å®¹",...]
    """
    dividing_list = []

    prompt_template = ChatPromptTemplate.from_messages([("system", system_template)])
    prompt = prompt_template.invoke({"full_text": text})
    dividing_response = model.invoke(prompt)
    try:
        dividing_list = json.loads(dividing_response.content)
    except json.JSONDecodeError:
        print("âŒ GPT å›å‚³éŒ¯èª¤å…§å®¹ï¼š", dividing_response.content)
        raise

    return dividing_list

def divide_text(file_id: str, text: str) -> list:
    #é€æ®µæ·±å…¥é åˆ†æ®µ
    system_template = """
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡æœ¬åˆ†æå·¥å…·ï¼Œè«‹æ ¹æ“šçµ¦å®šçš„æ–‡ç« å…§å®¹ï¼Œåš´æ ¼ä¾ç…§{check_response}å»ºè­°çš„æ®µè½æ•¸ï¼Œå°‡æ–‡ç« å…§å®¹æ‹†åˆ†æˆæœ‰æ„ç¾©çš„æ®µï¼Œè‹¥æ®µè½å«æœ‰æ¨™é¡Œè«‹å°‡æ¨™é¡Œä¹Ÿæ¶µè“‹å…¥è©²æ®µè½(æ¨™é¡Œèˆ‡æ®µè½é–“æœ‰ç©ºè¡Œä¹Ÿè¦è·Ÿè‘—ç©ºè¡Œ)ã€‚
    æ–‡ç« ï¼š{full_text}
    è«‹ä¸€å®šè¦å›å‚³ listæ ¼å¼
    ["é€™æ˜¯ç¬¬ä¸€æ®µå…§å®¹",é€™æ˜¯ç¬¬äºŒæ®µå…§å®¹",...]
    """
    dividing_list = []
    all_check_response = json.dumps(all_check(text), ensure_ascii=False)
    # å­˜å…¥ Redis
    r.set(f"file:{file_id}:all_check_response", all_check_response, ex=REDIS_TTL)

    prompt_template = ChatPromptTemplate.from_messages([("system", system_template)])
    prompt = prompt_template.invoke({"full_text": text, "check_response": all_check_response})
    dividing_response = model.invoke(prompt)
    try:
        dividing_list = json.loads(dividing_response.content)
    except json.JSONDecodeError:
        print("âŒ GPT å›å‚³éŒ¯èª¤å…§å®¹ï¼š", dividing_response.content)
        raise

    return dividing_list

# é€æ®µæ·±å…¥æ”¹å¯«çš„ Prompt æ¨¡æ¿
def rewrite_paragraph(rewrite_paragraph: str, response_content: str, QA: str, check_response_content: str) -> dict :
    system_template_rewrite = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡å­—ç·¨è¼¯å°ˆå®¶ï¼Œå°ˆé–€å¹«åŠ©é«˜ä¸­ç”Ÿä¿®æ”¹å¤§å­¸å…¥å­¸æ›¸é¢è³‡æ–™ã€‚æˆ‘å°‡æä¾›ä»¥ä¸‹å…§å®¹ï¼š
    1. æ¬²ä¿®æ”¹çš„æ®µè½ï¼š{rewrite_paragraph}
    2. åˆæ­¥è¨ºæ–·åˆ†æï¼š{modification_suggestion}
    3. å¼•å°å­¸ç”Ÿæ·±å…¥æ€è€ƒçš„å•é¡Œæ¸…å–®èˆ‡å›ç­”ï¼š{question_list}
    4. å…¨æ–‡å®Œæ•´ä¿®æ”¹å»ºè­°ï¼š{complete_suggestion}

    è«‹ä¾ä¸‹åˆ—æ­¥é©ŸåŸ·è¡Œï¼š
    ã€æ­¥é©Ÿ 1ï¼šæ•´åˆå•ç­”ã€‘
    - åƒ…ç´å…¥èˆ‡æœ¬æ®µè½å…§å®¹æœ€ç›¸é—œçš„ 1ï½2 çµ„å•ç­”ã€‚
    - è‹¥å­¸ç”Ÿå›ç­”ä¸­ç„¡å¯¦éš›ç¶“é©—ï¼Œè«‹ç•¥éè©²çµ„å•ç­”ã€‚

    ã€æ­¥é©Ÿ 2ï¼šæå‡ºä¿®æ”¹æ–¹å‘èˆ‡å…·é«”å»ºè­°ã€‘
    - çµåˆã€Œåˆæ­¥è¨ºæ–·åˆ†æã€èˆ‡ã€Œå…¨æ–‡ä¿®æ”¹å»ºè­°ã€ï¼Œæå‡ºæ­¤æ®µçš„æ”¹é€²æ–¹å‘ã€‚
    - ä¿®æ”¹å»ºè­°æ‡‰ç°¡æ½”ã€æœ‰é‚è¼¯ã€ç¬¦åˆé«˜ä¸­ç”Ÿèªæ°£ã€‚

    ã€æ­¥é©Ÿ 3ï¼šä¿®æ”¹æ®µè½ã€‘
    - æ”¹å–„èªå¥æµæš¢åº¦ã€é‚è¼¯èˆ‡èªªæœåŠ›ã€‚
    - è‹¥æœ‰éœ€è¦ï¼Œå¯è£œå……ä¾‹è­‰ï¼ˆé¿å…èˆ‡å…¶ä»–æ®µè½é‡è¤‡ï¼‰ã€‚
    - å¥å‹ä¿æŒæ¸…æ™°ç°¡å–®ï¼Œé¿å…éåº¦å­¸è¡“åŒ–ã€‚

    ã€æ­¥é©Ÿ 4ï¼šæ¢åˆ—ç´°é …ä¿®æ”¹ã€‘
    æ¯é …ä¿®æ”¹è«‹åˆ†é¡ï¼Œè‹¥ä¿®æ”¹åƒ…ç‚ºè©èªè®Šå‹•ï¼Œè«‹**åƒ…é¡¯ç¤ºè®Šå‹•è©èªçš„å‰å¾Œå°ç…§**ï¼›è‹¥æ¶‰åŠæ•´å¥èª¿æ•´ï¼Œæ‰é¡¯ç¤ºå®Œæ•´å¥å­ã€‚

    åˆ†é¡åŒ…å«ï¼š
    - ä¿®æ­£éŒ¯å­—ï¼ˆå«æ¨™é»ï¼‰
    - èšç„¦ä¸»é¡Œï¼ˆåˆªé™¤åé¡Œå¥ï¼‰
    - ç²¾ç°¡èªå¥ï¼ˆåˆªé™¤å†—è©ï¼‰
    - è£œå……å…§å®¹ï¼ˆè£œè¶³è¦é»æˆ–ä¾‹è­‰ï¼‰
    - ä¿®æ­£æ–‡å¥ï¼ˆèªæ³•æˆ–èªåºèª¿æ•´ï¼‰
    - å…¶ä»–å»ºè­°ï¼ˆèªæ°£ã€é‚è¼¯æˆ–é¢¨æ ¼æ”¹å–„ï¼‰


    è¼¸å‡ºæˆjsonï¼Œä»¥ä¸‹æ˜¯ç¯„ä¾‹ï¼Œè«‹å‹™å¿…è¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºã€ä¸å¯æœ‰```jsonç­‰æ ¼å¼å‡ºç¾ï¼š
    {{
        "è©²æ®µè½æ”¹é€²æ–¹å‘": "è«‹æä¾›æ”¹å¯«çš„ä¸»è¦æ–¹å‘ã€‚",
        "ç´°é …": [
        {{
        "é¡åˆ¥": "ä¿®æ­£éŒ¯å­—",
        "ä¿®æ”¹å»ºè­°": "ä¿®æ­£æ‹¼å­—éŒ¯èª¤ã€‚",
        "ä¿®æ”¹å‰å¥å­": "å …æŒä¸æ‡ˆ",
        "ä¿®æ”¹å¾Œå¥å­": "å …æŒä¸æ‡ˆ"}},
        {{
        "é¡åˆ¥": "ç²¾ç°¡èªå¥",
        "ä¿®æ”¹å»ºè­°": "åˆªé™¤é‡è¤‡è©èªã€‚",
        "ä¿®æ”¹å‰å¥å­": "å¯¦éš›å¯¦è¸",
        "ä¿®æ”¹å¾Œå¥å­": "å¯¦è¸"}},
        {{
        "é¡åˆ¥": "è£œå……å…§å®¹",
        "ä¿®æ”¹å»ºè­°": "è£œå……å…·é«”ä¾‹å­ã€‚",
        "ä¿®æ”¹å‰å¥å­": "æˆ‘å¾ˆé—œå¿ƒç¤¾æœƒè­°é¡Œã€‚",
        "ä¿®æ”¹å¾Œå¥å­": "æˆ‘é—œå¿ƒç¤¾æœƒè­°é¡Œï¼Œä¾‹å¦‚æˆ‘æ›¾åƒèˆ‡æ ¡å…§ç’°ä¿ç¤¾èˆ‰è¾¦çš„äºŒæ‰‹å¸‚é›†ã€‚"}},
        {{
        "é¡åˆ¥": "å…¶ä»–å»ºè­°",
        "ä¿®æ”¹å»ºè­°": "è«‹æä¾›èªæ°£ä¸Šçš„æ”¹å–„ã€‚",
        "ä¿®æ”¹å‰å¥å­":"é€™æ˜¯ä¸€å€‹ä¿®æ”¹å‰çš„å¥å­ç¤ºä¾‹ã€‚",
        "ä¿®æ”¹å¾Œå¥å­": "é€™æ˜¯ä¸€å€‹ä¿®æ”¹å¾Œçš„å¥å­ç¤ºä¾‹ã€‚"}},...
        ],
        "æ®µè½å®Œæ•´ä¿®æ”¹å‰å…§å®¹": "é€™æ˜¯ç¶“éæ”¹å¯«å‰çš„å®Œæ•´æ®µè½å…§å®¹..."
        "æ®µè½å®Œæ•´ä¿®æ”¹å¾Œå…§å®¹": "é€™æ˜¯ç¶“éæ”¹å¯«å¾Œçš„å®Œæ•´æ®µè½å…§å®¹..."
    }}

    """
    # å‰µå»º Prompt æ¨¡æ¿
    prompt_template_rewrite = ChatPromptTemplate.from_messages([("system", system_template_rewrite)])

    rewrite_prompt = prompt_template_rewrite.invoke({"rewrite_paragraph":rewrite_paragraph,"modification_suggestion": response_content,"question_list":QA, "complete_suggestion":check_response_content})
    rewrite_response = model.invoke(
        rewrite_prompt,
        temperature=0.7,  # å¢åŠ åˆ° 0.7-0.8ï¼Œæé«˜å‰µé€ æ€§
        top_p=0.9,     # ç•¥å¾®é™ä½ä»¥ä¿æŒå¤šæ¨£æ€§ä½†é¿å…éæ–¼å¥‡æ€ªçš„è¡¨é”
        #top_k=40      # å¢åŠ åˆ° 40-50ï¼Œæ“´å¤§å¯èƒ½çš„è©å½™é¸æ“‡ç¯„åœ
    )
    #print(rewrite_response.content)
    suggestion_dict = json.loads(rewrite_response.content)

    return suggestion_dict

def get_rewrite_suggestions(user_id: str, file_id: str, file_content: str):
    # æª¢æŸ¥è¼¸å…¥åƒæ•¸çš„æœ‰æ•ˆæ€§
    if not all([user_id, file_id, file_content]):
        raise ValueError("user_id, file_id å’Œ file_content ä¸èƒ½ç‚ºç©º")

    # å¾ Redis ç²å–å¿…è¦è³‡æ–™
    responses = {
        "first_response": r.get(f"file:{file_id}:diagnosed_result"),
        "QA_response": r.get(f"{user_id}:{file_id}:QA_response"),
        "all_check_response": r.get(f"file:{file_id}:all_check_response")
    }
    #QA_response = "Q: ä½ å­¸ç¿’ C++ å’Œ 3D å»ºæ¨¡çš„å‹•æ©Ÿæ˜¯ä»€éº¼ï¼Ÿé€™äº›æŠ€èƒ½å°ä½ çš„é•·æœŸè·æ¥­ç›®æ¨™æœ‰ä½•å½±éŸ¿ï¼ŸA: æˆ‘å°éŠæˆ²é–‹ç™¼å’Œç§‘æŠ€å¾ˆæœ‰èˆˆè¶£ï¼ŒC++ æ˜¯å¾ˆå¤šéŠæˆ²å¼•æ“çš„åŸºç¤ï¼Œè€Œ 3D å»ºæ¨¡å¯ä»¥å¹«æˆ‘å‰µé€ å‡ºéŠæˆ²ä¸­çš„è§’è‰²æˆ–å ´æ™¯ã€‚é€™äº›æŠ€èƒ½å¦‚æœå­¸å¾—å¥½ï¼Œå°‡ä¾†æƒ³é€²éŠæˆ²å…¬å¸æˆ–ç•¶è‡ªç”±é–‹ç™¼è€…éƒ½å¾ˆæœ‰å¹«åŠ©ã€‚Q: åœ¨è‡ªå­¸éç¨‹ä¸­æœ‰å“ªäº›å­¸ç¿’ç­–ç•¥æˆ–å·¥å…·å°ä½ ç‰¹åˆ¥æœ‰æ•ˆï¼ŸA: æˆ‘è¦ºå¾—çœ‹ YouTube æ•™å­¸å½±ç‰‡é…åˆå¯¦ä½œæœ€æœ‰æ•ˆï¼Œåƒæ˜¯é‚Šçœ‹é‚Šè·Ÿè‘—æ‰“ç¨‹å¼ç¢¼ã€‚å¦å¤–ä¹Ÿæœƒç”¨ç­†è¨˜æŠŠé‡é»æ•´ç†èµ·ä¾†ï¼Œæœ‰æ™‚é‚„æœƒä¸Šç¶²ç«™åƒæ˜¯ W3Schools æˆ–æ˜¯ Unity æ•™å­¸æ–‡ä»¶ã€‚Q: ä½ å¦‚ä½•è©•ä¼°è‡ªå·±çš„å­¸ç¿’æˆæœï¼Œä»¥ä¾¿èƒ½åœ¨æœªä¾†çš„å·¥ä½œæˆ–å­¸æ¥­ä¸­å……åˆ†å±•ç¾ï¼ŸA: æˆ‘æœƒåšä¸€äº›å°å°ˆæ¡ˆä¾†æ¸¬è©¦å­¸åˆ°çš„æ±è¥¿ï¼Œä¾‹å¦‚ç”¨ C++ åšå€‹å°éŠæˆ²æˆ–ç”¨ Blender å»ºæ¨¡åšå‡ºè§’è‰²ã€‚é€™äº›æˆæœå¯ä»¥æ”¾åœ¨ä½œå“é›†è£¡ï¼Œä»¥å¾Œæ‰¾å¯¦ç¿’æˆ–ç”³è«‹å¤§å­¸å¯ä»¥ç”¨ä¾†å±•ç¤ºå¯¦åŠ›ã€‚"
    
    # æª¢æŸ¥å¿…è¦è³‡æ–™æ˜¯å¦å­˜åœ¨
    for key, value in responses.items():
        if not value:
            raise ValueError(f"æ‰¾ä¸åˆ°{key}è³‡æ–™ï¼Œè«‹å…ˆå®Œæˆç›¸æ‡‰æ“ä½œ")

    # åˆ†æ®µå­˜å…¥ Redisï¼Œè¨­å®š TTL ç‚º 1 å°æ™‚
    try:
        dividing_list = divide_text(file_id, file_content)
    except Exception as e:
        print(f"åˆ†æ®µæ–‡æœ¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise
    r.set(f"{user_id}:{file_id}:dividing", json.dumps(dividing_list), ex=REDIS_TTL)

    def process_one(index, paragraph):
        try:
            if paragraph.strip():
                suggestion = rewrite_paragraph(
                    rewrite_paragraph=paragraph,
                    response_content=responses["first_response"],
                    QA=responses["QA_response"],
                    check_response_content=responses["all_check_response"]
                )
                r.set(f"{user_id}:{file_id}:suggestion:{index + 1}", json.dumps(suggestion), ex=REDIS_TTL)
                return {f"ç¬¬{index + 1}æ®µ": suggestion}
        except Exception as e:
            print(f"è™•ç†ç¬¬ {index + 1} æ®µæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

    # å¤šåŸ·è¡Œç·’è™•ç†æ‰€æœ‰æ®µè½
    results = []
    with ThreadPoolExecutor(max_workers=12) as executor:
        futures = [executor.submit(process_one, idx, para) for idx, para in enumerate(dividing_list)]
        for f in futures:
            result = f.result()
            if result:
                results.append(result)
    
    return results


def get_single_rewrite_suggestion(user_id: str, file_id: str, index: int):
    data = r.get(f"{user_id}:{file_id}:dividing")
    if not data:
        raise ValueError("æŸ¥ç„¡å¿«å–è³‡æ–™ï¼Œè«‹å…ˆå‘¼å« /allSuggestion å»ºç«‹æ®µè½")
    dividing_list = json.loads(data)

    first_response = r.get(f"file:{file_id}:diagnosed_result")
    QA_response = r.get(f"{user_id}:{file_id}:QA_response")
    all_check_response = r.get(f"file:{file_id}:all_check_response")

    suggestion = rewrite_paragraph(
                rewrite_paragraph=dividing_list[index],
                response_content=first_response,
                QA=QA_response,
                check_response_content=all_check_response
            )
    
    r.set(f"{user_id}:{file_id}:suggestion:{index+1}", json.dumps(suggestion), ex=REDIS_TTL)

    return suggestion

def accept_suggestion(user_id: str, file_id: str, paragraph_index: int, original_sentence: str):
    """
    åœ¨æŒ‡å®šæ®µè½ä¸­æ‰¾å‡º original_sentence å°æ‡‰çš„ç´°é …ï¼Œ
    ä¸¦ä»¥è©²ç´°é …ä¸­çš„ä¿®æ”¹å¾Œå¥å­è¦†è“‹åŸå¥ï¼Œç„¶å¾Œæ›´æ–° dividingã€‚
    """
    dividing_key = f"{user_id}:{file_id}:dividing"
    suggestion_key = f"{user_id}:{file_id}:suggestion:{paragraph_index}"

    dividing_data = r.get(dividing_key)
    suggestion_data = r.get(suggestion_key)

    if not dividing_data or not suggestion_data:
        raise ValueError("æ‰¾ä¸åˆ°æ®µè½æˆ–å»ºè­°è³‡æ–™")

    dividing_list = json.loads(dividing_data)
    suggestion = json.loads(suggestion_data)

    paragraph = dividing_list[paragraph_index-1]
    replaced = False

    for i, item in enumerate(suggestion["ç´°é …"]):
            before = item.get("ä¿®æ”¹å‰å¥å­")
            after = item.get("ä¿®æ”¹å¾Œå¥å­")
            if before and after and before.strip() == original_sentence.strip():
                paragraph = paragraph.replace(before, after, 1)
                del suggestion["ç´°é …"][i]  # åˆªé™¤è©²ç­†å»ºè­°
                replaced = True
                break  # åƒ…è™•ç†è©²ç­†ç´°é …ï¼Œé¿å…å…¶ä»–ç›¸ä¼¼å¥èª¤è“‹

    if not replaced:
        print(f"æ‰¾ä¸åˆ°å°æ‡‰çš„ä¿®æ”¹å»ºè­°ï¼š{original_sentence}")
        raise ValueError("æ‰¾ä¸åˆ°å°æ‡‰çš„ä¿®æ”¹å»ºè­°æˆ–åŸå¥ä¸åœ¨æ®µè½ä¸­")

    dividing_list[paragraph_index-1] = paragraph
    r.set(dividing_key, json.dumps(dividing_list))
    r.set(suggestion_key, json.dumps(suggestion))
    
def edit_paragraph(user_id: str, file_id: str, index: int, new_text: str) -> bool:
    """
    å„²å­˜ä½¿ç”¨è€…æ¥å—çš„æ®µè½æ”¹å¯«å…§å®¹åˆ° Redisã€‚
    """
    key = f"{user_id}:{file_id}:dividing"
    data = r.get(key)
    
    if not data:
        raise ValueError("Redis ä¸­æ‰¾ä¸åˆ°åŸå§‹æ®µè½ï¼Œè«‹å…ˆå‘¼å« /allSuggestion")

    try:
        dividing_list = json.loads(data)
    except json.JSONDecodeError:
        raise ValueError("Redis ä¸­çš„è³‡æ–™æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æ")

    # æ›´æ–°æŒ‡å®šæ®µè½
    if index < 1 or index > len(dividing_list):
        raise IndexError("æ®µè½ç´¢å¼•è¶…å‡ºç¯„åœ")

    dividing_list[index-1] = new_text

    # å„²å­˜å› Redisï¼ˆè¦†è“‹åŸæœ¬å…§å®¹ï¼‰
    r.set(key, json.dumps(dividing_list), ex=REDIS_TTL)
    print("edit_paragraph successfully")
    
def get_specified_paragraph(user_id: str, file_id: str, index: int):

    """
    æ ¹æ“šæ®µè½ç´¢å¼•å¾ Redis ä¸­å–å¾—æŒ‡å®šæ®µè½çš„æ‰€æœ‰ä¿®æ”¹å‰å¥å­ã€‚
    """
    # æ§‹å»º Redis éµ
    suggestion_key = f"{user_id}:{file_id}:suggestion:{index}"

    # å¾ Redis è®€å–è©²æ®µå»ºè­°
    data = r.get(suggestion_key)

    if not data:
        raise ValueError(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„æ®µè½å»ºè­°ï¼š{suggestion_key}")

    # è§£æè³‡æ–™
    suggestion = json.loads(data)
    # æå–æ®µè½çš„ä¿®æ”¹å‰å…§å®¹
    modification_before_sentences = []
    
    if "ç´°é …" in suggestion:
        for item in suggestion["ç´°é …"]:
            if "ä¿®æ”¹å‰å¥å­" in item:
                modification_before_sentences.append(item["ä¿®æ”¹å‰å¥å­"])


    if not modification_before_sentences:
        raise ValueError(f"è©²æ®µè½ç„¡ä¿®æ”¹å‰å¥å­ï¼š{suggestion_key}")

    return {
        "æ®µè½ç·¨è™Ÿ": index,
        "ä¿®æ”¹å‰å¥å­": modification_before_sentences
    }


## äº”ã€æœ€å¾Œè©•åˆ†

def evaluate_full_text(user_id: str, file_id: str) :
    """
    åˆä½µæ‰€æœ‰æ®µè½çš„åŸæ–‡èˆ‡æ”¹å¯«å¾Œå…§å®¹ï¼Œä¸¦é€å…¥ GPT è©•ä¼°æ•´é«”å“è³ªã€‚
    """

    # 1. å¾ Redis å–å‡º dividing_listï¼ˆåŸå§‹æ®µè½ï¼‰
    data = r.get(f"{user_id}:{file_id}:dividing")
    if not data:
        raise ValueError("Redis ä¸­æ‰¾ä¸åˆ°åˆ†æ®µå…§å®¹ï¼Œè«‹å…ˆåŸ·è¡Œ /allSuggestion å»ºç«‹æ®µè½")

    try:
        dividing_list = json.loads(data)
    except Exception as e:
        raise ValueError(f"ç„¡æ³•è§£æ Redis ä¸­çš„åˆ†æ®µè³‡æ–™ï¼š{str(e)}")

    # 2. åˆä½µåŸå§‹æ®µè½èˆ‡ä¿®æ”¹å¾Œæ®µè½
    full_text = "\n\n".join(dividing_list)



    # 4. å»ºç«‹ Prompt
    evaluation_template =evaluation_template = """
        ä»»å‹™ï¼šä½ æ˜¯ä¸€ä½æ‹›ç”Ÿè©•å¯©å§”å“¡ï¼Œè«‹æ ¹æ“šæä¾›çš„æ–‡ç« é€²è¡Œè©•ä¼°èˆ‡å»ºè­°ã€‚

        è«‹æ ¹æ“šä»¥ä¸‹å…­å€‹é¢å‘å°æ–‡ç« çµ¦åˆ†èˆ‡æä¾›å»ºè­°ï¼š
        1. éŒ¯å­—&æ¨™é»ç¬¦è™Ÿ
        2. åé¡Œ
        3. ç²¾ç°¡
        4. å¢é•·
        5. æ¶æ§‹
        6. å®Œæ•´åº¦

        è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›å‚³çµæœï¼ˆå‹™å¿…ç‚ºæœ‰æ•ˆ JSONï¼Œé¿å…å‡ºç¾ ```json æ¨™è¨˜æˆ–å¤šé¤˜çš„æ–‡å­—ï¼‰ï¼š

        {{
        "scores": [int, int, int, int, int, int, float],  // å…­é …è©•åˆ† + ç¸½å¹³å‡ (0~5 åˆ†)
        "scoreLabels": [
            "éŒ¯å­—&æ¨™é»ç¬¦è™Ÿ",
            "åé¡Œ",
            "ç²¾ç°¡",
            "å¢é•·",
            "æ¶æ§‹",
            "å®Œæ•´åº¦",
            "ç¸½åˆ†"
        ],
        "suggestions": [
            "é‡å°éŒ¯å­—èˆ‡æ¨™é»ç¬¦è™Ÿçš„å»ºè­°",
            "é‡å°åé¡Œå•é¡Œçš„å»ºè­°",
            "é‡å°æ˜¯å¦ç²¾ç°¡çš„å»ºè­°",
            "é‡å°æ˜¯å¦æ‡‰è£œå……å…§å®¹çš„å»ºè­°",
            "é‡å°æ®µè½æ¶æ§‹é‚è¼¯æ€§çš„å»ºè­°",
            "é‡å°å…§å®¹å®Œæ•´æ€§çš„å»ºè­°",
            "æ•´é«”ç¸½çµå»ºè­°"
        ]
        }}

        è«‹è©•ä¼°ä»¥ä¸‹æ–‡ç« ï¼š
        æ–‡ç« å…§å®¹ï¼š
        {end_text}

        è©•åˆ†æ¨™æº–ï¼š
        {evaluation_criteria}
        """


    prompt_template = ChatPromptTemplate.from_messages([("system", evaluation_template)])
    evaluation_prompt = prompt_template.invoke({
        "end_text": full_text,
        "evaluation_criteria": evaluation_criteria
    })

    response = model.invoke(evaluation_prompt)
    evaluation_result = json.loads(response.content)
    
    # å­˜å…¥Firebase
    db = firestore.client()
    evaluation_service = EvaluationService(db)
    evaluation_service.create_evaluation(
        user_id=user_id,
        file_id=file_id,
        scores=evaluation_result["scores"],
        score_labels=evaluation_result["scoreLabels"],
        suggestions=evaluation_result["suggestions"]
    )
    return evaluation_result
    

def get_statistics(user_id: str, file_id: str):
    """
    æ ¹æ“š Redis ä¸­ suggestion è³‡æ–™çµ±è¨ˆï¼šæ®µè½æ•¸ã€ä¿®æ”¹å»ºè­°ã€èªæ³•å•é¡Œã€è¡¨é”å„ªåŒ–ã€‚
    """
    dividing_key = f"{user_id}:{file_id}:dividing"
    dividing_data = r.get(dividing_key)
    if not dividing_data:
        raise ValueError("è«‹å…ˆå‘¼å« /allSuggestion å»ºç«‹æ®µè½")

    suggestions = []
    i = 1
    while True:
        s_key = f"{user_id}:{file_id}:suggestion:{i}"
        s_data = r.get(s_key)
        if not s_data:
            break
        suggestions.append(json.loads(s_data))
        i += 1

    num_paragraphs = len(suggestions)
    total_revisions = 0
    grammar_issues = 0
    expression_issues = 0
    other_suggestion=0
    
    for s in suggestions:
        for item in s["ç´°é …"]:
            total_revisions += 1
            if item.get("é¡åˆ¥") in ["ä¿®æ­£æ–‡å¥", "ä¿®æ­£éŒ¯å­—"]:
                grammar_issues += 1
            elif item.get("é¡åˆ¥") in ["ç²¾ç°¡èªå¥", "èšç„¦ä¸»é¡Œ", "è£œå……å…§å®¹","è£œè¶³è¦é»"]:
                expression_issues += 1
            else:
                other_suggestion += 1

    return {
        "æ®µè½": num_paragraphs,
        "ä¿®æ”¹å»ºè­°": total_revisions,
        "èªæ³•å•é¡Œ": grammar_issues,
        "è¡¨é”å„ªåŒ–": expression_issues,
        "å…¶ä»–å»ºè­°": other_suggestion
    }

## å…¶ä»–

def run_async_function(async_func):
    """
    åŸ·è¡ŒéåŒæ­¥å‡½æ•¸ä¸¦è¿”å›çµæœ
    
    Args:
        async_func: è¦åŸ·è¡Œçš„éåŒæ­¥å‡½æ•¸
        
    Returns:
        éåŒæ­¥å‡½æ•¸çš„åŸ·è¡Œçµæœ
    """
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(async_func())
    finally:
        loop.close()